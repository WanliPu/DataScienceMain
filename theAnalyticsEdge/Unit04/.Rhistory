alpha.fn=function(data, index){
with(data[index,],alpha(X,Y))
}
alpha.fn(Xy,1:100)
?with
alpha.fn=function(data, index){
with(data[index,],alpha(X1,Y))
}
with(data[index,],alpha(x1,y))
alpha.fn=function(data, index){
with(data[index,],alpha(x1,y))
}
alpha.fn(Xy,1:100)
alpha.fn=function(data, index){
with(data[index,],alpha(Xy$x1,y))
}
alpha.fn(Xy,1:100)
alpha.fn=function(data, index){
with(data[index,],alpha(Xy$X1,Xy$y))
}
alpha.fn(Xy,1:100)
set.seed(1)
alpha.fn (Xy,sample(1:100,100,replace=TRUE))
boot.out=boot(Xy,alpha.fn,R=1000)
boot.out
plot(boot.out)
?rep
library(SDSFoundations)
survey <- StudentSurvey
library(SDSFoundations)
survey <- StudentSurvey
View(survey)
chr(survey)
str(survey)
fivenum(survey$name_letters)
survey$name_letters.mean()
mean(survey$name_letters)
s
mean(survey$name_letters)
chr()
mean(survey$name_letters)
summary(survey$name_letters)
sd(survey$name_letters)
hist(survey$name_letters)
fivenum(survey$name_letters)
xbar5 <-rep(NA, 1000)
for (i in 1:1000)
{x <-sample(survey$name_letters, size =5)
xbar5[i] <-  mean(x)}
hist(xbar5,xlim=c(2,10))
mean(xbar5)
sd(xbar5)
sd(survey$name_letters)/sqrt(5)
mean(survey$name_letters)
sd(survey$name_letters)
xbar5 <-rep(NA, 1000)
for (i in 1:1000)
{x <-sample(survey$name_letters, size =5)
xbar5[i] <-  mean(x)}
# Graph the histogram of 1,000 sample means.
hist(xbar5,xlim=c(2,10))
# Calculate the mean and sd of the sampling distribution.
mean(xbar5)
sd(xbar5)
# Compare to the std dev predicted by the CTL.
sd(survey$name_letters)/sqrt(5)
#Repeat for samples of size n=15
xbar15 <-rep(NA, 1000)
for (i in 1:1000)
{x <-sample(survey$name_letters, size =15)
xbar15[i] <- mean(x)}
hist(xbar15,xlim=c(2,10))
mean(xbar15)
sd(xbar15)
sd(survey$name_letters)/sqrt(15)
#Repeat for samples of size n=25
xbar25 <-rep(NA, 1000)
for (i in 1:1000)
{x <-sample(survey$name_letters, size =25)
xbar25[i] <- mean(x)}
hist(xbar25,xlim=c(2,10))
mean(xbar25)
sd(xbar25)
sd(survey$name_letters)/sqrt(25)
hist(survey$happy)
fivenum(survey$happy)
mean(survey$happy)
sd(survey$happy)
xbar5 <-rep(NA, 1000)
for (i in 1:1000)
{x <-sample(survey$happy, size =5)
xbar5[i] <-  mean(x)}
# Graph the histogram of 1,000 sample means.
hist(xbar5,xlim=c(50,100))
# Calculate the mean and sd of the sampling distribution.
mean(xbar5)
sd(xbar5)
# Compare to the std dev predicted by the CTL.
sd(survey$happy)/sqrt(5)
#Repeat for samples of size n=15
xbar15 <-rep(NA, 1000)
for (i in 1:1000)
{x <-sample(survey$happy, size =15)
xbar15[i] <- mean(x)}
hist(xbar15,xlim=c(50,100))
mean(xbar15)
sd(xbar15)
sd(survey$happy)/sqrt(15)
#Repeat for samples of size n=25
xbar25 <-rep(NA, 1000)
for (i in 1:1000)
{x <-sample(survey$happy, size =25)
xbar25[i] <- mean(x)}
hist(xbar25,xlim=c(50,100))
mean(xbar25)
sd(xbar25)
sd(survey$happy)/sqrt(25)
library(SDSFoundations)
survey <- StudentSurvey
str(survey)
hist(survey$austin)
mean(survey$austin)
sd(survey$austin)
sd(survey$austin) / sqrt(10)
xbar10 <-rep(NA, 1000)
for (i in 1:1000)
{x <-sample(survey$austin, size =10)
xbar10[i] <- mean(x)}
hist(xbar10,xlim=c(0,15))
qt(c(.025, .975), df=24)
qt(c(.025, .975), df=6)
qt(0.05, df=6)
library(SDSFoundations)
bull <- BullRiders
str(bull)
USA <-bull[bull$Country=="USA",]
# Summarize the bull rider weights
mean(USA$Weight)
sd(USA$Weight)
# Visualize the weight distribution
hist(USA$Weight, main='Histogram of US Bull Rider Weights',xlab='Weight (lbs)')
# Run the single sample t-test
t.test(USA$Weight, mu=190)
View(USA)
View(USA)
hist(bull$YearBorn, main = 'Histogram of Bull Rider Weights, xlab= 'Weight (lbs)')
mean(USA$Weight)
sd(USA$Weight)
t.test(USA$Weight, mu=190)
View(bull)
rider2014_5 = bull[bull$Events14 >= 5, ]
mean(rider2014_5$RidePer14)
sd(rider2014_5$RidePer14)
t.test(rider2014_5$RidePer14, mu=0.5)
hist(rider2014_5$RidePer14, main='Histogram of US Bull Rider Weights',xlab='Weight (lbs)')
bull$earnings_per = bull$Earnings12/bull$Events12
View(bull)
hist(rider2014_5$RidePer14,xlab='Weight (lbs)')
hist(bull$earnings_per)
bull$newvariable <- log(bull$originalvariable)
bull$newvariable <- log(bull$earnings_per)
hist(bull$newvariable)
mean(bull$newvariable)
?mean
mean(bull$newvariable, na.rm = FALSE)
mean(bull$newvariable, na.rm = TRUE)
t.test(bull$newvariable, mu=8.846387)
exp(8.572169 )
exp(9.120605)
potatochips = c(29.4	29	28.4	28.8	28.9	29.3	28.5	28.2)
potatochips = c(29.4, 29, 28.4, 28.8, 28.9, 29.3, 28.5, 28.2)
mean(potatochips)
sd(potatochips)
t.test(potatochips, mu=28.5)
qt(c(.025, .975), df=7)
qt(.95, df=24)
qt(c(0.05, 0.95), df=11)
qt(c(0.025, 0.975), 9)
qt(0.05, 9)
qt(0.95, 9)
sd(c(-1, 1, -2, -2))
sd(c(-1, 1, -2, -2))/2
qt(c(0.025, 0.975), 3)
qt(0.95, 3)
qt(0.05, 3)
qt(0.05, 4)
qt(0.05, 3)
qt(c(0.025, 0.975), 4)
qt(c(0.025, 0.975), 3)
t.test(c(-1, 1, -2, -2), 0)
t.test(c(-1, 1, -2, -2), mu = 0)
library(SDSFoundations)
post <- PostSurvey
library(SDSFoundations)
post <- PostSurvey
View(post)
underclass_happy <- post$happy[post$classification=='Freshman'|post$classification=='Sophomore']
upperclass_happy <- post$happy[post$classification=='Junior'|post$classification=='Senior']
# Check the normality assumption
hist(underclass_happy, xlab='Underclassman Happiness', main='Percent of Time Happy')
hist(upperclass_happy, xlab='Upperclassman Happiness', main='Percent of Time Happy')
t.test(underclass_happy, upperclass_happy)
mean(underclass_happy)
post$diff_happy <- post$happy - post$post_happy
# Check the normality assumption
hist(post$diff_happy, xlab= 'Difference in Happiness over the Semester', main = 'Happy-Post Happy')
# Run dependent t-test
t.test(post$happy, post$post_happy, paired=T)
post$diff_hw = post$hw_hours_college - post$hw_hours_HS
mean(post$diff_hw)
t.test(post$hw_hours_college, post$hw_hours_HS, alternative = 'greater')
?t.test
t.test(post$hw_hours_college, post$hw_hours_HS, alternative = 'greater', paired = TRUE)
t.test(post$diff_hw, alternative = 'greater')
greek = post[post$greek == yes, ]
greek = post[post$greek == "yes", ]
nongreek = post[post$greek == "no", ]
mean(greek$sleep_Sat) - mean(nongreek$sleep_Sat)
t.test(greek$sleep_Sat, nongreek$sleep_Sat, alternative = 'less')
hist(greek$sleep_Sat)
hist(nongreek$sleep_Sat)
hist(post$diff_hw)
hist(greek$sleep_Sat)
hist(nongreek$sleep_Sat)
nursing = post[post$major == "Nursing", ]
biology = post[post$major == "Biology", ]
hist(nursing$diff_hw)
hist(biology$diff_hw)
t.test(nursing$diff_hw, biology$diff_hw)
qt(0.95, 25)
qt(0.05, 25)
qt(0.05, 15)
leftright <- read.csv("C:/Users/Wanli/OneDrive/R/FoundationsOfDataAnalysisPart2/leftright.csv")
View(leftright)
sd(leftright$left)
sd(leftright$right)
leftright$diff = leftright$left - leftright$right
sd(leftright$diff)
sd(leftright$diff)/sqrt(16)
t.test(leftright$diff, alternative = 'greater')
t.test(leftright$diff)
chisq.test(c(38, 28, 24))
chisqt?
fdf
library(SDSFoundations)
res = TempskiResilience
library("SDSFoundations", lib.loc="~/R/win-library/3.2")
remove.packages("SDSFoundations", lib="~/R/win-library/3.2")
install.packages("C:/Users/Wanli/Downloads/SDSFoundations_1.4.zip", repos = NULL, type = "win.binary")
install.packages("C:/Users/Wanli/Downloads/SDSFoundations_1.4.zip", repos = NULL, type = "win.binary")
install.packages("C:/Users/Wanli/Downloads/SDSFoundations_1.4.zip", repos = NULL, type = "win.binary")
library(SDSFoundations)
res <- TempskiResilience
View(res)
clin <- res[res$Group == "Clinical Sciences",]
#Question One
#Intial Correlations
vars <- c("QoL", "BDI")
cor(clin[,vars])
#RQ1 Model
ov_mod <- lm(QoL ~ BDI, data=clin)
summary(ov_mod)
confint(ov_mod)
summary(ov_mod)
summary(ov_mod)
summary(ov_mod)
?summary
?corr.test
plot(ov_mod, which=1)
cutoff <- 4/(ov_mod$df)
plot(ov_mod, which=4, cook.levels=cutoff)
# Question Two
#Initial correlations
vars <- c("MS.QoL", "DREEM.S.SP", "DREEM.A.SP", "Resilience", "BDI", "Age")
cor(clin[,vars], use="pairwise.complete.obs")
#Test the initial correlations
library(psych)
corr.test(clin[,vars], use="pairwise.complete.obs")
?corr.test
#RQ2 Model
ms_mod <- lm(MS.QoL ~ DREEM.S.SP + DREEM.A.SP + Resilience + BDI + Age, data=clin)
summary(ms_mod)
confint(ms_mod)
#Diagnostics
library(car)
vif(ms_mod)
plot(ms_mod, which=1)
cutoff <- 4/(ms_mod$df)
plot(ms_mod, which=4, cook.levels=cutoff)
#Put model into context
lmBeta(ms_mod)
?lmBeta
vars <- c("MS.QoL", "DREEM.S.SP", "DREEM.A.SP", "Resilience", "BDI", "Age")
cor(clin[,vars], use="pairwise.complete.obs")
#Test the initial correlations
library(psych)
corr.test(clin[,vars], use="pairwise.complete.obs")
ov_mod <- lm(QoL ~ BDI, data=clin)
summary(ov_mod)
cor(clin[,vars], use="pairwise.complete.obs")
vars <- c("MS.QoL", "DREEM.S.SP", "DREEM.A.SP", "Resilience", "BDI", "Age")
cor(clin[,vars], use="pairwise.complete.obs")
ms_mod <- lm(MS.QoL ~ DREEM.S.SP + DREEM.A.SP + Resilience + BDI + Age, data=clin)
summary(ms_mod)
confint(ms_mod)
#Diagnostics
library(car)
vif(ms_mod)
plot(ms_mod, which=1)
cutoff <- 4/(ms_mod$df)
plot(ms_mod, which=4, cook.levels=cutoff)
#Put model into context
lmBeta(ms_mod)
round(pCorr(ms_mod), 4)
1 - 0.0134
vars <- c("QoL", "BDI")
cor(clin[,vars])
#RQ1 Model
ov_mod <- lm(QoL ~ BDI, data=clin)
summary(ov_mod)
confint(ov_mod)
#Diagnostics
plot(ov_mod, which=1)
cutoff <- 4/(ov_mod$df)
plot(ov_mod, which=4, cook.levels=cutoff)
# Question Two
#Initial correlations
vars <- c("MS.QoL", "DREEM.S.SP", "DREEM.A.SP", "Resilience", "BDI", "Age")
cor(clin[,vars], use="pairwise.complete.obs")
#Test the initial correlations
library(psych)
corr.test(clin[,vars], use="pairwise.complete.obs")
?corr.test
#RQ2 Model
ms_mod <- lm(MS.QoL ~ DREEM.S.SP + DREEM.A.SP + Resilience + BDI + Age, data=clin)
summary(ms_mod)
basic <- res[res$Group == "Basic Sciences",]
View(basic)
basic <- res[res$Group == "Basic Sciences",]
vars <- c("MS.QoL", "WHOQOL.ENV", "WHOQOL.PH", "WHOQOL.PSY", "WHOQOL.SOC", "WHOQOL.ENV")
cor(basic[,vars], use="pairwise.complete.obs")
vars <- c("MS.QoL", "WHOQOL.PH", "WHOQOL.PSY", "WHOQOL.SOC", "WHOQOL.ENV")
cor(basic[,vars], use="pairwise.complete.obs")
ms_mod <- lm(MS.QoL ~ WHOQOL.ENV + WHOQOL.PH + WHOQOL.PSY + WHOQOL.SOC + WHOQOL.ENV, data=clin)
summary(ms_mod)
summary(ms_mod)
confint(ms_mod)
#Diagnostics
library(car)
vif(ms_mod)
plot(ms_mod, which=1)
cutoff <- 4/(ms_mod$df)
plot(ms_mod, which=4, cook.levels=cutoff)
lmBeta(ms_mod)
?lmBeta
round(pCorr(ms_mod), 4)
ms_mod <- lm(MS.QoL ~ WHOQOL.ENV + WHOQOL.PH + WHOQOL.PSY + WHOQOL.SOC + WHOQOL.ENV, data=basic)
summary(ms_mod)
lmBeta(ms_mod)
?lmBeta
round(pCorr(ms_mod), 4)
ms_mod <- lm(MS.QoL ~ WHOQOL.ENV + WHOQOL.PH + WHOQOL.PSY + WHOQOL.SOC + WHOQOL.ENV, data=basic)
summary(ms_mod)
lmBeta(ms_mod)
round(pCorr(ms_mod), 4)
ms_mod <- lm(BDI ~ Female + Age + State.Anxiety + Trait.anxiety, data=clin)
summary(ms_mod)
summary(ms_mod)
confint(ms_mod)
#Diagnostics
library(car)
vif(ms_mod)
plot(ms_mod, which=1)
cutoff <- 4/(ms_mod$df)
plot(ms_mod, which=4, cook.levels=cutoff)
#Put model into context
lmBeta(ms_mod)
round(pCorr(ms_mod), 4)
qf(.95, df1=4, df2=88)
qf(.05, df1=4, df2=88)
qf(.95, df1=4, df2=88)
qf(.95, df1=4, df2=1)
qf(.95, df1=4, df2=88)
install.packages("caTools")
stevens = read.csv("stevens.csv")
setwd("C:/Users/Wanli/OneDrive/dsmain/theAnalyticsEdge/Unit04")
stevens = read.csv("stevens.csv")
str(stevens)
library(caTools)
set.seed(3000)
spl = sample.split(stevens$Reverse, SplitRatio = 0.7)
Train = subset(stevens, spl==TRUE)
Test = subset(stevens, spl==FALSE)
install.packages("rpart")
library(rpart)
install.packages("rpart.plot")
library(rpart.plot)
StevensTree = rpart(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, method="class", minbucket=25)
prp(StevensTree)
PredictCART = predict(StevensTree, newdata = Test, type = "class")
table(Test$Reverse, PredictCART)
(41+71)/(41+36+22+71)
# ROC curve
library(ROCR)
PredictROC = predict(StevensTree, newdata = Test)
PredictROC
pred = prediction(PredictROC[,2], Test$Reverse)
perf = performance(pred, "tpr", "fpr")
plot(perf)
as.numeric(performance(pred, "auc")@y.values)
StevensTree2 = rpart(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, method="class", minbucket=5)
prp(StevensTree2)
summary(StevensTree2)
prp(StevensTree)
summary(StevensTree)
StevensTree3 = rpart(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, method="class", minbucket=100)
prp(StevensTree3)
summary(StevensTree3)
install.packages("randomForest")
library(randomForest)
# Build random forest model
StevensForest = randomForest(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, ntree=200, nodesize=25 )
Train$Reverse = as.factor(Train$Reverse)
Test$Reverse = as.factor(Test$Reverse)
summary(Train)
PredictForest = predict(StevensForest, newdata = Test)
table(Test$Reverse, PredictForest)
table(Test$Reverse, PredictForest > 0.5)
PredictForest
StevensForest = randomForest(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, ntree=200, nodesize=25 )
PredictForest = predict(StevensForest, newdata = Test)
PredictForest
table(Test$Reverse, PredictForest)
set.seed(100)
StevensForest = randomForest(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, ntree=200, nodesize=25 )
# Make predictions
PredictForest = predict(StevensForest, newdata = Test)
PredictForest
table(Test$Reverse, PredictForest)
(43+74)/(40+37+19+74)
set.seed(200)
StevensForest = randomForest(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, ntree=200, nodesize=25 )
# Make predictions
PredictForest = predict(StevensForest, newdata = Test)
PredictForest
table(Test$Reverse, PredictForest)
(44+76)/(40+37+19+74)
install.packages("caret")
library(caret)
install.packages("e1071")
library(e1071)
# Define cross-validation experiment
numFolds = trainControl( method = "cv", number = 10 )
cpGrid = expand.grid( .cp = seq(0.01,0.5,0.01))
# Perform the cross validation
train(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, method = "rpart", trControl = numFolds, tuneGrid = cpGrid )
StevensTreeCV = rpart(Reverse ~ Circuit + Issue + Petitioner + Respondent + LowerCourt + Unconst, data = Train, method="class", cp = 0.18)
# Make predictions
PredictCV = predict(StevensTreeCV, newdata = Test, type = "class")
table(Test$Reverse, PredictCV)
(59+64)/(59+18+29+64)
summary(StevensTreeCV)
prp(StevensTreeCV)
Claims = read.csv("ClaimsData.csv")
str(Claims)
table(Claims$bucket2009)/nrow(Claims)
library(caTools)
set.seed(88)
spl = sample.split(Claims$bucket2009, SplitRatio = 0.6)
ClaimsTrain = subset(Claims, spl==TRUE)
ClaimsTest = subset(Claims, spl==FALSE)
mean(ClaimsTrain$age)
View(ClaimsTrain)
summary(ClaimsTrain)
table(ClaimsTest$bucket2009, ClaimsTest$bucket2008)
(110138 + 10721 + 2774 + 1539 + 104)/nrow(ClaimsTest)
PenaltyMatrix = matrix(c(0,1,2,3,4,2,0,1,2,3,4,2,0,1,2,6,4,2,0,1,8,6,4,2,0), byrow=TRUE, nrow=5)
PenaltyMatrix
table(ClaimsTest$bucket2009, PredictTest)
table(ClaimsTest$bucket2009, PredictTest)
(110138 + 7787 + 3427 + 201 + 174)/nrow(ClaimsTest)
(110138 + 10721 + 2774 + 1452 + 104)/nrow(ClaimsTest)
PenaltyMatrix2 = matrix(c(0, 2, 4, 6, 8), byrow=TRUE, nrow=5)
PenaltyMatrix2
table(ClaimsTest$bucket2009, ClaimsTest$bucket2008)
sum(table(ClaimsTest$bucket2009, ClaimsTest$bucket2008))
sum(table(ClaimsTest$bucket2009, ClaimsTest$bucket2008), 1)
table(ClaimsTest$bucket2009)
bucket2009 = matrix(c(122978, 34840, 16390, 7937, 1057), byrow=TRUE, nrow=5)
as.matrix(table(ClaimsTest$bucket2009))
as.matrix(table(ClaimsTest$bucket2009))*PenaltyMatrix2
sum(as.matrix(table(ClaimsTest$bucket2009))*PenaltyMatrix2)
sum(as.matrix(table(ClaimsTest$bucket2009))*PenaltyMatrix2)
as.matrix(table(ClaimsTest$bucket2009, ClaimsTest$bucket2008))*PenaltyMatrix
sum(as.matrix(table(ClaimsTest$bucket2009, ClaimsTest$bucket2008))*PenaltyMatrix)/nrow(ClaimsTest)
sum(as.matrix(table(ClaimsTest$bucket2009))*PenaltyMatrix2)/nrow(ClaimsTest)
summary(ClaimsTrain)
ClaimsTree = rpart(bucket2009 ~ age + alzheimers + arthritis + cancer + copd + depression + diabetes + heart.failure + ihd + kidney + osteoporosis + stroke + bucket2008 + reimbursement2008, data=ClaimsTrain, method="class", cp=0.00005)
prp(ClaimsTree)
PredictTest = predict(ClaimsTree, newdata = ClaimsTest, type = "class")
table(ClaimsTest$bucket2009, PredictTest)
(114141 + 16102 + 118 + 201 + 0)/nrow(ClaimsTest)
# Penalty Error
as.matrix(table(ClaimsTest$bucket2009, PredictTest))*PenaltyMatrix
sum(as.matrix(table(ClaimsTest$bucket2009, PredictTest))*PenaltyMatrix)/nrow(ClaimsTest)
# New CART model with loss matrix
ClaimsTree = rpart(bucket2009 ~ age + alzheimers + arthritis + cancer + copd + depression + diabetes + heart.failure + ihd + kidney + osteoporosis + stroke + bucket2008 + reimbursement2008, data=ClaimsTrain, method="class", cp=0.00005, parms=list(loss=PenaltyMatrix))
# Redo predictions and penalty error
PredictTest = predict(ClaimsTree, newdata = ClaimsTest, type = "class")
table(ClaimsTest$bucket2009, PredictTest)
(94310 + 18942 + 4692 + 636 + 2)/nrow(ClaimsTest)
sum(as.matrix(table(ClaimsTest$bucket2009, PredictTest))*PenaltyMatrix)/nrow(ClaimsTest)
